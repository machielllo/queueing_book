% arara: pdflatex: { shell: yes, interaction: nonstopmode }
% arara: pythontex: {verbose: yes, rerun: modified }
% arara: pdflatex: { shell: yes, interaction: nonstopmode }
% arara: clean: { extensions: [ aux, blg, idx, ilg, ind, log, out, pytxcode, rel, toc ] }
% !arara: clean: { files: [ ans.tex, hint.tex] }

\input{header}

\section{$M^X/M/1$ Queue Length Distribution}\label{sec:batch-arrivals}


In~\cref{sec:mxm1-queue:-expected,sec:mg1} we established the Pollaczek-Khinchine formula for the waiting times of the $M^X/M/1$ queue and the $M/G/1$ queue, respectively.
To compute more difficult performance measures such as the loss probability $\P{\L>n}$, we need expressions for the stationary distribution $\pi(n)$.
Here we present a numerical, recursive, scheme to compute these probabilities.


\newthought{We can again} use level-crossing arguments to find $\{\pi(n)\}$.
However, the reasoning that led to the level-crossing equation~\cref{eq:15} needs to be generalized because, at the arrival of a batch containing many items, multiple levels will be up-crossed, see~\cref{fig:levelcrossing}.


\begin{figure}[ht]
\centering
\begin{tikzpicture}[scale=1,
 %Define standard arrow tip
 >=stealth',
 %Define style for boxes
 circ/.style={
 circle,
 draw=black,
 thick,
 minimum size=1.cm,
 inner sep=0pt,
 text centered
 },
 % Define arrow style
 pil/.style={
 ->,
 thick,
 shorten <=2pt,
 shorten >=2pt}
]

\draw[dashed, thick] node at (5,-1.5) [below] {level $n$}
(5,-1.5) -- (5,3);

\node[circ] (n-2) {$n-2$};

%\node[circ, right=of n-2] (n-1) {$n-1$} edge[loop below, thick] node[midway, fill=white] {$\lambda f(0)$} (n-1);
\node[circ, right=of n-2] (n-1) {$n-1$};

\node[circ, right=of n-1] (n) {$ n $}
 edge[pil,<-, bend left=45] node[below] {$\lambda f(1)$} (n-1.south east);
\node[circ, right=of n] (n+1) {$n+1$}
 edge[pil,bend left=45] node[midway, fill=white] {$\mu$} (n.south east);
\node[above=of n+1] (inf) {}
 edge[pil, <-, bend right=45] node[midway, fill=white] {$\lambda G(0)$} (n.north east)
 edge[pil, <-, bend right=45] node[midway, fill=white] {$\lambda G(1)$} (n-1.north east)
 edge[pil, <-, bend right=45] node[midway, fill=white] {$\lambda G(2)$} (n-2.north east)
;
\end{tikzpicture}

\caption{When $L(t)=n$, the arrival of any batch crosses level $n$ from below, but when $L(t)=n-1$, only a batch larger than $1$ ensures a crossing of level $n$, and so on.} \label{fig:levelcrossing}
\end{figure}

\newthought{Let us first} guess what could be the appropriate generalization of $\lambda \pi(n) = \mu \pi(n+1)$.\sidenote{i.e., the level-crossing equations of the $M/M/1$ queue.}
The down-crossings are easy: since items are served one-by-one, we still must have $\mu \pi(n+1)$.
For the upcrossings, let us focus for the moment on the arrivals that see $m$, with $m\leq n$, in the system. The arrival stream of such customers is thinned with probability $\pi(m)$\sidenote{Compare \cref{ex:32} and \cref{ex:1}}. Thus, the arrival rate of  jobs that see $m$ upon arrival is~$\lambda \pi(m)$.
By PASTA the arrival process $\{N(u), u\geq t\}$ is independent of $\{L(s), s< t\}$, hence this thinned process is also Poisson.

When an arriving job sees $m$ in the system, and level $n$ has to be up-crossed, the batch size of this job must contain more than $n-m$ items.
The rate at which such jobs arrive must be $G(n-m)\pi(m)\lambda$ as  $G(n-m)$ is the probability that the job size is larger than $n-m$.  Noting that the batch sizes are independent of the arrival times, we obtain yet again a Poisson process, but with rate $\lambda \pi(m) G(n-m)$.

Finally, to compute the up-crossing rate of level $n$, we merge\sidenote{Compare \cref{ex:l-103} and \cref{ex:41}.}
all these thinned Poisson processes to form a Poisson process with rate $\lambda \sum_{m=0}^n \pi(m) G(n-m)$.

By level-crossing, the up-crossing and down-crossing rates must match, and therefore,
\begin{equation}\label{eq:42}
\lambda \sum_{m=0}^n \pi(m) G(n-m) = \mu \pi(n+1).
\end{equation}
It is easy to see that~\cref{eq:42} holds for the $M/M/1$ queue.\sidenote{~\cref{ex:27}}
Moreover, we can use it to derive $\E\L$.\sidenote{~\cref{ex:73}}

\newthought{We formalize} the above reasoning as follows.
Define
\begin{equation*}
 A(m,n,t) := \sum_{k=1}^{A(t)}\1{\L(A_k-) = m}\1{B_k > n-m}
\end{equation*}
as the number of jobs up to time $t$ that see $m$ in the system upon arrival and have batch size larger than $n-m$.
From~\cref{fig:levelcrossing} we see that $A(n,m,t)$ counts the number of up-crossings of level $n$ up to time $t$.

As earlier, we are interested in the limit $A(n,m,t)/t$ as $t\to\infty$.
If we follow the reasoning of~\cref{sec:poisson-arrivals-see}, we obtain by multiplying and dividing,
\begin{equation}\label{eq:16}
 \frac{A(m,n,t)}t = \frac{A(t)}t \frac{A(m,t)}{A(t)}\frac{A(m,n,t)}{A(m,t)}.
\end{equation}
We already know that $A(t)/t\to\lambda$ and $A(m,t)/A(t)\to\pi(m)$; so, let us  provide  an interpretation for the third term.

If we fill in the definitions, we get
\begin{equation*}
 \frac{A(m,n,t)}{A(m,t)} =  \frac{\sum_{k=1}^{A(t)}\1{\L(A_k-) = m, B_k > n-m}}
{\sum_{k=1}^{A(t)}\1{\L(A_k-) = m}}.
\end{equation*}
In words, this is the fraction of those jobs that see $m$ in the system upon arrival and have size $> n-m$.
But recall that we assumed that  $\{B_k\}$  are independent of what jobs see upon arrival.
Thus, we can just as well count all jobs of size $>n-m$ along a sample path instead of those that see $m$ upon arrival; in the limit the statistics must be the same. Therefore
\begin{equation*}
\lim_{t\to\infty}  \frac{\sum_{k=1}^{A(t)}\1{\L(A_k-) = m, B_k > n-m}}
{\sum_{k=1}^{A(t)}\1{\L(A_k-) = m}} = \lim_{t\to\infty}
\frac{\sum_{k=1}^{A(t)}\1{B_k > n-m}}{A(t)}= G(n-m).
\end{equation*}


By level-crossing, the number of up- and down-crossing  must satisfy
\begin{equation*}
\left|\sum_{m=0}^n A(m,n,t) -  D(n,t)\right| \leq 1.
\end{equation*}
Then, by combining the above, dividing by~$t$, and taking the limit $t\to\infty$, we obtain~\cref{eq:16}.


\newthought{It is left} to find the normalization constant.
As~\cref{eq:42} does not lead to a closed form expression for $\pi(n)$, such as~\cref{eq:23}, we have to specify a criterion to stop this iterative procedure.
We discuss three different strategies to cope with this problem.

For actual computations we suppose henceforth that the batch size $B$ is finite and bounded by some $N$.
Then, as $G(n)=0$ for $n\geq N$, we can simplify~\cref{eq:42} to
\begin{equation*}
\mu \pi(n+1) = \lambda \sum_{m=0}^{\min\{n, N-1\}} \pi(n-m) G(m).
\end{equation*}



\newthought{The simplest strategy} is to `ignore the problem'.
Just set $\pi(0)=1$ to start the iteration, then compute the first $M$, 10 say, terms, and take $\sum_{i=0}^M \pi(i)$ as the normalization constant.
With this, $\E\L \approx \sum_{n=0}^M n \pi(n)$.

\begin{pyblock}[][numbers=left,frame=lines]
import numpy as np


def compute_pi(f, M):
    pi = np.ones(M + 1)
    F = np.cumsum(f)
    G = np.ones_like(F) - F
    N = len(G)

    for n in range(M):
        pi[n + 1] = sum(pi[n - m] * G[m] for m in range(min(n + 1, N)))
        pi[n + 1] *= labda / mu
    return pi / pi.sum()

M = 10
labda, mu = 1, 3
f = np.array([0, 1, 1, 1])
f = f / f.sum()

pi = compute_pi(f, M)
EL = sum(n * pi[n] for n in range(len(pi)))
\end{pyblock}
When running this code, we get $\E\L = \py{np.round(EL,3)}$.

But is $M=10$ large enough for this estimate to be approximately correct?
\begin{pycode}[][numbers=left,frame=lines]
EB = sum(k * fk for k, fk in enumerate(f))
rho = labda * EB / mu
EB2 = sum(k * k * fk for k, fk in enumerate(f))
VB = EB2 - EB * EB
C2 = VB / EB / EB
EL_exact = (1 + C2) / 2 * rho / (1 - rho) * EB + rho / (1 - rho) / 2
\end{pycode}
Using~\cref{eq:43}  to compute  exact value, we obtain $\E\L = \py{np.round(EL_exact,3)}$.
Clearly, simply stopping at some arbitrary value is not a viable procedure.

A better criterion is perhaps to stop iterating at some $M$ when $\pi(M)\ll 1$.\sidenote{In line 6 we choose to implement \pyv{p} as a dictionary, because we do not yet know how many terms we need before satisfying the stopping criterion.}
\begin{pyblock}[][numbers=left,frame=lines]
def compute_pi_2(f, eps):
    F = np.cumsum(f)
    G = np.ones_like(F) - F
    N = len(G)

    pi, n = {}, 0
    pi[n] = 1

    while pi[n] > eps:
        pi[n + 1] = sum(pi[n - m] * G[m] for m in range(min(n + 1, N)))
        pi[n + 1] *= labda / mu
        n += 1

    norm = sum(pi[n] for n in pi.keys())
    return {n: pi[n] / norm for n in pi.keys()}


pi = compute_pi_2(f, eps=0.001)
EL = sum(n * pi[n] for n in pi.keys())
\end{pyblock}
Now we find $\E\L = \py{np.round(EL,3)}$.
This is indeed better, but $\epsilon = 0.001$ is not yet small enough: the second digit is wrong.\sidenote{Observe how important it is to have exact results such as~\cref{eq:43} to check the results of numerical algorithms.}



\newthought{The second method} is exact, but more involved: we block demand above some level $M$.
There are three common policies to decide which items in a batch to accept.
\begin{enumerate}
\item Complete acceptance: accept all batches that arrive when the system contains $K$ or fewer items, and reject the entire batch otherwise.\sidenote{~\cref{ex:9}}
\item Partial acceptance: accept whatever fits of a batch, and reject the rest.\sidenote{~\cref{ex:45}}
\item Complete rejection: if a batch does not fit entirely into the system, it will be rejected completely.\sidenote{~\cref{ex:l-156}}
\end{enumerate}
Once we have recursions similar to~\cref{eq:42} we can again obtain $\{\pi(n)\}$. Since the recursions stop after level $M$, there is a finite number of recusions, hence we can solve them numerically without much problems.

\newthought{The third method} relies on the fact that the numbers $\pi(n)$ decrease geometrically fast for $n$ sufficiently large.
Let us check this for the numerical example we studied above.
\begin{marginfigure}
\begin{pycode}[ignore]
import numpy as np
import matplotlib.pylab as plt
import tikzplotlib
from matplotlib import style
style.use('ggplot')

def compute_pi(f, M):
    pi = np.ones(M + 1)
    F = np.cumsum(f)
    G = np.ones_like(F) - F
    N = len(G)

    for n in range(M):
        pi[n + 1] = sum(pi[n - m] * G[m] for m in range(min(n + 1, N)))
        pi[n + 1] *= labda / mu
    return pi / pi.sum()

labda, mu = 1, 3
f = np.array([0, 1, 1, 1])
f = f / f.sum()

pi = compute_pi(f, M=10)


plt.yscale('log')
plt.plot(pi, label=r"$\pi(n)$")
plt.xlabel("$n$")
plt.legend()
# plt.show()
plot = tikzplotlib.get_tikz_code(axis_height='5cm', axis_width='6cm')
print(plot)
\end{pycode}
\end{marginfigure}
In the figure at the right we plot $\log (\pi(n))$  as a function of $n$. Clearly, $\pi(n), n\geq 5$ seems to decrease as a straight line.


To provide some intuition for this fact, observe that  for $N<n\leq 2N-1$,
\begin{equation*}
  \pi(n+1) = \frac{\lambda}{\mu} \sum_{m=0}^{N-1}\pi(n-m)G(m) < \frac{\lambda}{\mu} \sum_{m=0}^{N-1} G(m)  = \rho < 1.
\end{equation*}
as $\pi(n) < 1$ for $n\leq N$. But then, for $2N< n \leq 3N-1$,
\begin{equation*}
  \pi(n+1) = \frac{\lambda}{\mu} \sum_{m=0}^{N-1}\pi(n-m)G(m) < \frac{\lambda}{\mu} \sum_{m=0}^{N-1} G(m)\rho  = \rho^2,
\end{equation*}
and so on. However, this is a crude upper bound for the decay rate, because $\pi(n)<1$ is not very sharp.

We can do better by substituting the form $\pi(n)= C \alpha^n$ into~\cref{eq:42} for $k>N$.
Then $\alpha$ should be a root of the equation $\lambda \sum_{m=0}^{N-1} \alpha^m G(N-1-m) = \mu \alpha^{N}$.
Now this is a polynomial (in $\alpha$) of degree $N$, which has $N$ roots in general.
We leave it to the interested reader to study the theoretical ramifications of this method, for instance, why should $\alpha$ be the largest root?


\begin{exercise}\label{ex:27}
 Show that~\cref{eq:42} reduces to $\lambda \pi(n) = \mu \pi(n+1)$ for the $M/M/1$ case.
\begin{solution}
  In the $M/M/1$ queue, $G(0)=1$ and $G(1)=G(2)=\cdots = 0$.
  Thus, $\sum_{m=0}^n G(n-m) \pi(m) = G(0)\pi(n)=\pi(n)$.
\end{solution}
\end{exercise}



\begin{exercise}\label{ex:73}
Use~\cref{eq:42}
\marginpar{This is an important check both on \cref{eq:43} and~\cref{eq:42}.}
in $\E{\L} = \sum_{n=0}^\infty n \pi(n)$ to derive~\cref{eq:43}.
\begin{hint}
  Show first that
\begin{equation*}
 \mu \E \L =\mu \sum_{n=0}^\infty n \pi(n) = \lambda \frac{\E{B^2}}2 + \lambda \E B \E \L +\lambda \frac{\E B}2.
\end{equation*}
\end{hint}
\begin{solution}
 We use that $\mu \pi(n) =\lambda \sum_{i=0}^{n-1} \pi(i) G(n-1-i)$ and the results of the exercises of~\cref{sec:mxm1-queue:-expected} to see that
\begin{align*}
 \mu \E \L
 &=\sum_{n=0}^\infty n\, \mu \pi(n), \quad \text{now substitute for $\mu \pi(n)$ the recursion~\cref{eq:42}}, \\
& =\lambda \sum_{n=0}^\infty n \sum_{i=0}^{n-1} \pi(i) G(n-1-i)
 =\lambda \sum_{n=0}^\infty n \sum_{i=0}^\infty \1{i<n} \pi(i) G(n-1-i) \\
& =\lambda \sum_{i=0}^\infty \pi(i) \sum_{n=0}^\infty \1{i<n} n G(n-1-i)
 =\lambda \sum_{i=0}^\infty \pi(i) \sum_{n=i+1}^\infty n G(n-1-i) \\
& =\lambda \sum_{i=0}^\infty \pi(i) \sum_{n=0}^\infty (n+i+1) G(n)
 =\lambda \sum_{i=0}^\infty \pi(i) \left[\sum_{n=0}^\infty n G(n) +(i+1) \sum_{n=0}^\infty G(n)\right] \\
 &=\lambda \sum_{i=0}^\infty \pi(i)\sum_{n=0}^\infty n G(n) +\lambda \E B \sum_{i=0}^\infty \pi(i) (i+1) \\
 &=\lambda \sum_{i=0}^\infty \pi(i) \frac{\E{B^2} -\E B}2 + \lambda \E B (\E \L +1) \\
 &= \lambda \frac{\E{B^2} -\E B}2 + \lambda \E B \E \L +\lambda \E B \\
 &= \lambda \frac{\E{B^2} }2 + \lambda \E B \E \L +\lambda \frac{\E B}2.
\end{align*}
Dividing both sides by $\mu$ and using that $\lambda \E B/\mu = \rho$, we obtain
\begin{equation*}
E \L = \lambda \frac{\E{B^2}}2 \E S + \rho \E \L + \frac\rho2.
\end{equation*}
By bringing $\rho \E \L$ to the LHS, the RHS becomes equal to~\cref{eq:17}.
\end{solution}
\end{exercise}



\begin{exercise}\label{ex:l-154}
 Why is $\pi(n)=\delta(n)$ not true for the $M^X/M/1$  queue?
\begin{solution}
Jobs can arrive in batches larger than 1, but items leave one by one.
\end{solution}
\end{exercise}



\begin{exercise}\label{ex:9}
 Derive a set of recursions for the $M^X/M/1/K$ queue with complete acceptance.
\begin{solution}
 The complete-acceptance policy is actually quite simple. As any
 batch will be accepted when $n\leq K$, the queue length is not
 bounded. Only when the number of items in the system is larger than
 $K$, we do not accept jobs.
 \begin{equation*}
 \mu \pi(n+1) =
 \begin{cases}
 \lambda \sum_{m=0}^n \pi(m) G(n-m), & \text{ for } n\leq K,\\
 \lambda \sum_{m=0}^K \pi(m) G(n-m), & \text{ for } n> K.
 \end{cases}
 \end{equation*}
\end{solution}
\end{exercise}



\begin{exercise}\label{ex:45}
 Derive a set of recursions analogous to~\cref{eq:42} to compute $\pi(n)$ for the $M^X/M/1/K$ queue with partial acceptance.
\begin{solution}
  For the partial acceptance case, any job is accepted, but the system only admits whatever fits.
  As level $n\in {0,1,\ldots,K-1}$ is still up-crossed by any batch of size at least $n-m$ when the system is in state $m$, the formula for the up-crossing rate is identical to the case without this acceptance policy.
  Hence, $\mu \pi(n+1) = \lambda \sum_{m=0}^n \pi(m) G(n-m)$, for $n=0,1,\ldots, K-1$.
\end{solution}
\end{exercise}


\begin{exercise}\label{ex:l-156}
 Derive a set of recursions for the $M^X/M/1/K$ queue with complete rejection.
\begin{solution}
  Suppose a batch of size $k$ arrives when the system contains $m$ items.
  When $m+k \leq K$, the batch can be accepted since the entire batch will fit into the queue, otherwise it will be rejected.
  Further, level $n, 0\leq n < K$, can only be crossed when $m+k > n$.
  Thus, for $n=0,\ldots, K-1$,
 \begin{align*}
 \mu \pi(n+1) &= \lambda \sum_{m=0}^n \pi(m) \P{n-m < B \leq K-m} \\
&=\lambda \sum_{m=0}^n \pi(m) [G(n-m)-G(K-m)],
 \end{align*}
 Let us check this for some simple cases.
 First, when $K\to \infty$, then $G(K-m)\to 0$, so we get our earlier result.
 Second, take $n=K$.
 Then $G(n-m)-G(K-m)=0$ for all $m$, so that the RHS is 0, as it should.
 Third, take $n=0$ and $K=1$, then $\mu \pi(1)= \lambda \pi(0)$.
 This also makes sense.
\end{solution}
\end{exercise}


\input{trailer}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
