% arara: pdflatex: { shell: yes, interaction: nonstopmode }
% arara: pythontex: {verbose: yes, rerun: modified }
% arara: pdflatex: { shell: yes, interaction: nonstopmode }
% arara: clean: { extensions: [ aux, blg, idx, ilg, ind, log, out, pytxcode, rel, toc ] }
% !arara: clean: { files: [ ans.tex, hint.tex] }
\input{header}
\section{(Limits of) Empirical Performance Measures}
\label{sec:limits-of-empirical}

In~\cref{sec:constr-gg1-queu} we use the arrival process $\{A(t)\}$ and the service times $\{S_k\}$ to construct the waiting times $\{\W_k\}$, sojourn times $\{J_k\}$, and the number in the system $\{\L(t)\}$. If the queueing system is rate-stable, we can sensibly define several long-run average performance measures.




\newthought{Define the} expected \recall{waiting time in queue} as
\begin{equation*}
 \E{\W} = \lim_{n\to\infty} \frac 1 n\sum_{k=1}^n W_{k}.
\end{equation*}
Note that this is the limit of waiting times as \emph{observed by arriving jobs}:
 the first job has to wait $W_1$ in queue, the second $W_2$, and so on.\sidenote{ We colloquially say that a statistic based on the sampling of arriving jobs is `as seen by arrivals'.}
The \recall{expected sojourn time} is defined likewise.
The \emph{distribution} of the waiting time as seen by arrivals can be found by counting:
\begin{align}\label{eq:48}
 \P{\W \leq x} &= \lim_{n\to\infty} \frac 1n\sum_{k=1}^n \1{\W_k\leq x}.
\end{align}
For the distribution of $J$  a similar definition applies.
The \recall{average number of jobs} in the system is given by
\begin{equation}\label{eq:EQ}
\E\L = \lim_{n\to\infty}\frac 1 n \sum_{k=1}^n L(A_k-),
\end{equation}
since $L(A_k-)$ is the number of jobs in the system at the arrival epoch of the $k$th job.
The distribution of $L$ follows also from counting, compare~\cref{eq:48}.


\newthought{A related set} of performance measures follows by tracking the system's behavior over time and taking the \emph{time-average}.\sidenote{Now we say that such performance measures are as `seen by the server'.}

Assuming the limit exists, we use~\cref{eq:14} to define the \recall{time-average number of jobs} as
\sidenote{Even though the symbols are the same, this expectation is not necessarily the same as~\cref{eq:EQ}.}
\begin{equation} \label{eq:46}
 \E\L = \lim_{t\to\infty} \frac 1 t\int_0^t L(s) \d s.
\end{equation}
 The \emph{time-average fraction of time the system contains at most $m$ jobs} is defined as
\begin{equation*}
 \P{\L\leq m} =\lim_{t\to\infty} \frac 1 t\int_0^t \1{\L(s)\leq m} \d s.
\end{equation*}
%Again, this (time-average) probability need not be the same as what customers see upon arrival.

\newthought{Proving the existence} of the above limits requires a considerable amount of mathematics.\sidenote{See \citet{Asmussen2003} if you are interested.}
Here we sidestep all such fundamental issues, and simply assume all is well defined in our examples.
The limiting random variables are known as the \recall{steady-state} or \recall{stationary} limits.

\newthought{Besides that the} transient analysis of queueing systems is difficult,\sidenote{See~\cref{sec:queu-proc-as}} there is an another reasons why much queueing theory is concerned with the analysis of the system in steady state.  Steady-state models provide formulas\sidenote{i.e., structural insight}, rather than numbers, with which we can compute performance measures of reasonable quality. Hence, for many practical purposes, a steady-state analysis suffices.

\begin{exercise}\label{ex:l-165}
Design a queueing system to show that the average number of jobs in the system as seen by the server can be very different from what customers see upon arrival.
\begin{hint}
Consider a queueing system with constant service and constant inter-arrival times.
\end{hint}
\begin{solution}
 Take $L(0) = 0$, $X_k = 10$ and $S_k = 10-\epsilon$ for some tiny
 $\epsilon>0$. Then $L(t) = 1$ nearly all of the time. In fact,
 $\lim_{t\to\infty}t^{-1}\int_0^t L(t) \d t= 1-\epsilon/10$. However, $L(A_k-)=0$ for all $k$.
\end{solution}
\end{exercise}


\begin{exercise}\label{ex:90}
 If $L(t)/t \to 0$ as $t\to\infty$, can it still be true that $\E{\L}>0$?
\begin{solution}
 \begin{equation*}
 \E{\L} = \lim_{t\to\infty} \frac 1 t \int_0^t L(s) \d s \neq \lim_{t\to\infty} \frac{\L(t)}t.
 \end{equation*}
If $L(t)=1$ for all $t$, $\E{\L} =1 $, but $L(t)/t \to 0$.
\end{solution}
\end{exercise}


\begin{exercise}\label{ex:l-166}
Consider \marginpar{Performance measures obtained by sampling in  discrete-time queueing models require some extra attention.}
 the discrete-time model specified by~\cref{eq:31}. We assume that $a_{k}$ is a \emph{batch} of jobs arriving in period~$k$ \emph{after} the departures $d_k$ have left.
Provide a simulation to estimate  $\P{\L\leq m}$ for a situation in which  the first job of the batch sees $L_{k-1} - d_k$ jobs in the system,
the second sees $L_{k-1}-d_k + 1$ jobs, and so on.
\begin{solution}
The idea is like this. The dictionary \pyv{L_count} counts the number of jobs that see $0$, $1$, and so on, in the system.

Here is the code. As an aside, it was hard to make it this simple.
\begin{pyconsole}
from collections import defaultdict

L_count = defaultdict(int)

a = [0, 2, 5, 1, 2]
c = [0, 1, 1, 1, 1]

d = [0] * len(a)
L = [0] * len(a)

for k in range(1, len(a)):
    d[k] = min(L[k - 1], c[k])
    L[k] = L[k - 1] + a[k] - d[k]
    for i in range(a[k]):
        L_count[L[k - 1] - d[k] + i] += 1


# normalize
tot = sum(L_count.values())
L_dist = {k: v / tot for k, v in L_count.items()}

print(L_count)
print(L_dist)
\end{pyconsole}

\end{solution}
\end{exercise}

\input{trailer}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
