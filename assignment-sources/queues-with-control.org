#+title:  Control of Queues
#+author: Nicky D. van Foreest
#+date: 2022:01:19

#+STARTUP: indent
#+STARTUP: overview
#+PROPERTY: header-args:shell :exports both
#+PROPERTY: header-args:emacs-lisp :eval no-export
#+PROPERTY: header-args:python :eval no-export
# +PROPERTY: header-args:python :session  :exports both   :dir "./figures/" :results output

#+OPTIONS: toc:nil author:nil date:nil title:t

#+LATEX_CLASS: subfiles
#+LATEX_CLASS_OPTIONS: [assignments]

#+begin_src emacs-lisp :exports results :results none :eval export
  (make-variable-buffer-local 'org-latex-title-command)
  (setq org-latex-title-command (concat "\\chapter{%t}\n"))
#+end_src


* TODO Set theme and font size for YouTube                         :noexport:

# +begin_src emacs-lisp :eval no-export
#+begin_src emacs-lisp
(modus-themes-load-operandi)
(set-face-attribute 'default nil :height 200)
#+end_src

#+RESULTS:



* Intro

We simulate queues that are controlled by some policy that uses information on  waiting time or queue length. We also develop algorithms to compute the state probabilities of the $M/G/1$ queue under the policies.


* Blocking on waiting time

In this assignment we investigate queues under certain control rules. First we focus on blocking, then on switching on and off the server depending on the queue length.

Suppose we don't allow jobs to enter the system when the waiting time becomes too long. A simple rule is the block job $k$ when $W_k \geq T$, for some threshold $T.

How to simulate that?

** A start with no blocking

Before doing something  difficult, I tend to start from a situation that I do understand, which, in this case, is the single server queue without blocking.

Here is our standard code. With this we can find parameters that are suitable to see that blocking will have an impact. (Suppose $\lambda=1$, $\mu=1000$, $T=100$, we will see no job being blocked during any simulation, at least not in this universe.)
#+begin_src python
import numpy as np


np.random.seed(3)

num = 10000
labda = 1
mu = 1.1 * labda
T = 5
X = np.random.exponential(scale=1 / labda, size=num)
S = np.random.exponential(scale=1 / mu, size=len(X))
S[0] = 0

W = np.zeros_like(S)
for k in range(1, len(S)):
    W[k] = max(W[k - 1] + S[k - 1] - X[k], 0)

print(W.mean(), W.max())
print((W >= T).mean()) # this
#+end_src

#+begin_exercise
Run the code and check that indeed long waiting times do occur. What does the ~this~ line do?
#+end_exercise

#+begin_exercise
Give the Kendall notation for the queueing model that  we simulate here.
#+begin_hint
It's  not the $D/D/1$ queue.
#+end_hint

#+end_exercise


** A hack to implement blocking

Here is a dirty hack to implement blocking. When $W_k\geq T$, job $k$ should not enter. That means that its service time should not be added to the waiting time. But not adding the service time can be achieved by setting $S_k=0$. To realize this, change the for loop to

#+begin_src python
for k in range(1, len(S)):
    W[k] = max(W[k - 1] + S[k - 1] - X[k], 0)
    if W[k] >= T:
        S[k] = 0
#+end_src

#+begin_exercise
Run this code and check its effect on $\E W$, $\V W$, and $\max\{W\}$. Explain how it can occur that the maximum can still be larger than $T$.
#+begin_hint
Check the section in the queueing book on the $M^X/M/1$ queue, in particular the section on blocking. Which blocking method do we include here?
#+end_hint
#+end_exercise

** A better method

As a matter of principle, I don't like the code of the previous section. In my opinion such hacks are a guarantee on bugs that can be very hard to find later. Mind, with this trick I am changing my primary data, in this case the service times.  Reuse these service times at a  later point in the code, for instance for a comparison with other models or for testing, has become impossible. And if I forget this (when I use this code maybe half a year later), then finding the bug will be very hard. Hence, as a golden rule: don't touch the primary data.

However, modifying this code so that I can block seems not straightforward.

#+begin_exercise
The recursion we use, i.e.,
#+begin_src python
for k in range(1, len(S)):
    W[k] = max(W[k - 1] + S[k - 1] - X[k], 0)
#+end_src
assumes that job $k-1$ is accepted. Suppose that ~W[k] >= T~ so that job $k$ is blocked. Explain that with this recursion, we now have a problem to compute the waiting time for job $k+1$.
#+begin_hint
We want to block  job $k$ when $W_{k}\geq T$. That means that job $k+1$ should not see $S_{k}$, but (as far as I see)  we cannot convert that into an elegant recursion for $W_{k+1}$
#+end_hint
#+end_exercise

Here is better code.

#+begin_src python
W = np.zeros_like(S)
I = np.ones_like(S)
for k in range(1, len(S)):
    W[k] = max(W[k - 1] + S[k - 1] * I[k - 1] - X[k], 0)
    if W[k] >= T:
        I[k] = 0

print(W.mean(), I.mean())
#+end_src

#+begin_exercise
What does the vector ~I~ represent?
#+begin_hint
If ~I[k] == 1~, then what happens to job $k$?
#+end_hint
#+end_exercise

** Some other blocking rules

There are other rules to block jobs.

#+begin_exercise
In this code,
#+begin_src python
W = np.zeros_like(S)
I = np.ones_like(S)
for k in range(1, len(S)):
    W[k] = max(W[k - 1] + S[k - 1] * I[k - 1] - X[k], 0)
    if W[k] + S[k] >= T:
        I[k] = 0

print(W.mean(), W.max(), I.mean())
#+end_src
how does the rule below block jobs?
#+end_exercise

#+begin_exercise
Likewise,
#+begin_src python
W = np.zeros_like(S)
V = np.ones_like(S)
for k in range(1, len(S)):
    W[k] = max(W[k - 1] + V[k - 1] - X[k], 0)
    V[k] = min(T - W[k], S[k])

print(W.mean(), W.max(), S.mean() - V.mean())
#+end_src
how does the rule below block jobs? What is the meaning of ~V~?
#+end_exercise

* Batch queues and blocking on waiting time

Let us now set up a simulation to see the combined effect of batch arrivals and  blocking on waiting time.

Recall, in the queueing book we discuss some methods to block jobs in the $M^X/M/1$ queue  when the queue length (not the waiting time) is too long. We tackle blocking on queue length in a separate section below.

** Again start without blocking

We need a slightly different way to generate service times. When a batch of $B_k$ jobs arrives at time $A_{k}$, then the service time added to the waiting is the sum of the service times of all $B_{k}$ jobs in the batch.


#+begin_src python
import numpy as np
from scipy.stats import expon

np.random.seed(3)

num = 100000
labda = 1
mu = 1.1 * labda
X = np.random.exponential(scale=1 / labda, size=num)
B = np.random.randint(1, 2, size=num)
S = expon(scale=1 / mu)

W = np.zeros_like(X)
for k in range(1, len(W)):
    W[k] = max(W[k - 1] + S.rvs(B[k]).sum() - X[k], 0)

print(S.mean(), W.mean(), W.max())
rho = labda / mu
print(rho**2 / (1 - rho))
#+end_src

#+RESULTS:
: 0.9090909090909091 8.905084979504103 69.31370721304536
: 9.090909090909086

#+begin_exercise
Explain how this code works.
#+end_exercise

#+begin_exercise
Run the code. Why do I take ~B~ as it is here? Why should ~W.mean()~ and $\rho^2/(1-\rho)$ be approximately equal
#+begin_hint
Why is this the $M/M/1$ queue when the batches  ~B = np.random.randint(1, 2, size=num)~? (Recall my obsession with testing code.)
#+end_hint
#+end_exercise

** Include blocking

Here is the code with a blocking rule.
#+begin_src python
import numpy as np
from scipy.stats import expon

np.random.seed(3)

num = 1000
labda = 1
mu = 3.1 * labda
T = 5
X = np.random.exponential(scale=1 / labda, size=num)
B = np.random.randint(1, 5, size=num)
S = expon(scale=1 / mu)

W = np.zeros_like(X)
V = np.zeros_like(W)
for k in range(1, len(W)):
    W[k] = max(W[k - 1] + V[k - 1] - X[k], 0)
    V[k] = S.rvs(B[k]).sum() if W[k] < T else 0

print(S.mean() * B.mean() - V.mean())
print(W.mean(), W.max())
print(np.isclose(V, 0).mean())
print((V <= 0).mean())  # this
#+end_src

#+begin_exercise
Explain how the code works. What do the printed KPIs denote?  Finally, why is the ~this~ line very dangerous to use, hence to be avoided? (Use ~np.isclose~ instead!)
#+end_exercise



* Blocking on queue length

Blocking on queue length is quite a bit harder with a simulation in continuous time because we need to keep track of the number of jobs in the system. (Recall in discrete time the recursions to compute $\{L\}$ are easy, while in continuous time the recursions for $\{W\}$ or $\{J\}$ are easy.)

** Start without blocking

As before, I start from a code that I really understand, and then I extend it to a situation that I find more difficult.  So, here is code to find the system length $L$ at /arrival/ epochs $\{A_k\}$.

#+begin_src python
import numpy as np

np.random.seed(3)

num = 10000
labda = 1
mu = 1.5 * labda
X = np.random.exponential(scale=1 / labda, size=num)
A = np.zeros(len(X) + 1)
A[1:] = X.cumsum()
S = np.random.exponential(scale=1 / mu, size=len(A))
S[0] = 0
D = np.zeros_like(A)
L = np.zeros_like(A, dtype=int)

idx = 0
for k in range(1, len(A)):
    D[k] = max(D[k - 1], A[k]) + S[k]
    while D[idx] < A[k]:
        idx += 1
    L[k] = k - idx

rho = labda / mu
print(L.mean(), rho/(1-rho), L.max())
print((L == 0).mean(), 1 - rho)
print((L == 1).mean(), (1 - rho)*rho)
#+end_src

#+RESULTS:
: 1.9834016598340165 1.9999999999999998 19
: 0.32216778322167783 0.33333333333333337
: 0.22507749225077492 0.22222222222222224

#+begin_exercise
Explain how this computes ~L[k]~. Do we count the system length as seen upon arrival, or does ~L[k]~ include  job $k$, i.e., the job that just arrived?
#+begin_hint
When the while loop terminates, is ~idx~ the index of the last departure, or does it point to the job that is the first to leave?
#+end_hint
#+end_exercise

#+begin_exercise
Just to check that you  really understand: why is there no problem with the statement ~(L == 0)~?
#+begin_hint
Is ~L~ a float?
#+end_hint
#+end_exercise

#+begin_exercise
Why do I compare ~L.mean()~ to $\rho/(1-\rho)$ and not to $\rho^{2}/1-\rho)$?
#+begin_hint
What is $\rho^2/(1-\rho)$?
#+end_hint
#+end_exercise

#+begin_exercise
Change $\mu$ to $1.05\lambda$. Now the results of the simulation are not very good if ~num=1000~ or so. Making ~num~ much larger does the job, though.
#+end_exercise


** Include blocking

It might seem that we are now ready to implement a continuous time queueing system with blocking on the queue length. Why not merge the ideas we developed above? Well, because this does not work.

(If you like a challenge, stop reading here, and try to see how far you can get with developing a simulation for this situation.)


Only after having worked for 3 hours I finally saw `the light'. As a matter of fact, I needed a new data structure, a ~deque~ from which we can pop and append jobs at either end of a list.  Here is the code.

#+begin_src python
from collections import deque
import numpy as np

np.random.seed(3)

num = 10000
labda = 1
mu = 1.2 * labda
T = 5
X = np.random.exponential(scale=1 / labda, size=num)
A = np.zeros(len(X) + 1)
A[1:] = X.cumsum()
S = np.random.exponential(scale=1 / mu, size=len(A))
S[0] = 0
D = np.zeros_like(A)
L = np.zeros_like(A, dtype=int)

Q = deque(maxlen=T + 1)
for k in range(1, len(A)):
    while Q and D[Q[0]] < A[k]:
        Q.popleft()
    L[k] = len(Q)
    if len(Q) == 0:
        D[k] = A[k] + S[k]
        Q.append(k)
    elif len(Q) < T:
        D[k] = D[Q[-1]] + S[k]
        Q.append(k)
    else:
        D[k] = A[k]
#+end_src

#+begin_exercise
Read the documentation of how a ~deque~ works, then explain the code.
#+end_exercise

#+begin_exercise
At first I had these lines:
#+begin_src python
elif len(Q) < T:
    Q.append(k)
    D[k] = D[Q[-1]] + S[k]
#+end_src
Why is that wrong?
#+begin_hint
To what job does ~Q[-1]~ point to? It's one to far!
#+end_hint
#+end_exercise

#+begin_exercise
What goes wrong with this code:
#+begin_src python
if len(Q) < T:
    D[k] = max(D[Q[-1]], A[k]) + S[k]
    Q.append(k)
#+end_src
#+begin_hint
When ~Q~ is empty (i.e., ~len(Q)~ is 0), then what is ~Q[-1]~?
#+end_hint
#+end_exercise

#+begin_exercise
What queueing discipline would result if we would use the ~pop()~ and ~appendleft()~ methods of a ~deque~?
#+begin_hint
Does it matter whether we push jobs from right to left through a quue, rather then from left to right?
#+end_hint
#+end_exercise

#+begin_exercise
What queueing discipline would result if we would use the ~pop()~ and ~append()~ methods of a ~deque~?
#+begin_hint
It's not FIFO.
#+end_hint
#+end_exercise


#+begin_exercise
Run this code with ~T=100~ and compare this with the queueing system without blocking. Why should you get the same results? (Realize that this is a check on the correctness of our code.)
#+begin_hint
Is ~L.max()~ larger than 100 for this simulation?
#+end_hint
#+end_exercise


Glue the next code (for the theoretical model) at the end of the previous code.
#+begin_src python
rho = labda / mu
p = np.ones(T + 1)
for i in range(1, T + 1):
    p[i] = rho * p[i - 1]
p /= p.sum()
for i in range(T + 1):
    print((L == i).mean(), p[i])
#+end_src

#+begin_exercise
Now set ~T=5~ and ~num = 10000~ or so. Run the code. Why do the result agree with the theoretical model? Why is this the $M/M/1$ queue?
#+end_exercise

In fact, I used the above theoretical model to check whether the simulation was correct. (My first 20 or so attempts weren't.)

* An algorithm for the $M/G/1$ queue with blocking

In the queueing book we develop an algoritm to compute $\pi(n)$. Here we implement this, use this as another test on the simulator, and improve our understanding of queueing systems.

** The algorithm

This is the code.

#+begin_src python
import numpy as np
from scipy.integrate import quad
from scipy.stats import expon

np.random.seed(3)

labda = 1
mu = 1.2 * labda
T = 5
S = expon(scale=1 / mu)


def g(j, x):
    res = np.exp(-labda * x) * (labda * x) ** j * S.pdf(x)
    return res / np.math.factorial(j)


f = np.zeros(T + 1)
for j in range(T + 1):
    f[j] = quad(lambda x: g(j, x), 0, np.inf)[0]

F = f.cumsum()
G = 1 - F

pi = np.ones(T + 1)
for n in range(T):
    pi[n + 1] = pi[0] * G[n]
    pi[n + 1] += sum(pi[m] * G[n + 1 - m] for m in range(1, n + 1))
    pi[n + 1] /= f[0]

pi /= pi.sum()
print(pi)
#+end_src

#+begin_exercise
Which formulas (give the numbers) of the queueing book have we implemented?
#+end_exercise

#+begin_exercise
Run this code after the computation of ~f~.
#+begin_src python
j = 2
print(mu / (mu + labda) * (labda / (labda + mu)) ** j, f[j])
#+end_src
Why should these numbers be the same?
#+end_exercise


#+begin_exercise
Run the code for $\mu=0.3$ and compare the numerical results to what you get from:
#+begin_src python
rho = labda / mu
p = np.ones(T + 1)
for i in range(1, T + 1):
    p[i] = rho * p[i - 1]
p /= p.sum()
print(pi)
#+end_src
Explain why you should get the same numbers.
#+end_exercise

#+begin_exercise
When the service times are contant, explain that this code computes ~f~ correctly:
#+begin_src python
from scipy.stats import expon, uniform, poisson
# include useful code here
f = poisson(labda / mu).pmf(range(T + 1))
#+end_src
Then change the ~S~ in the simulation part to
#+begin_src python
S = np.ones(len(A)) / mu
#+end_src
Run the code and include your results; of course the simulation and the algoritm should give more or less the same results.
#+end_exercise

#+begin_exercise
As another good example, take $S\sim \Unif{0, 2/\mu}$. The relevant code changes are this:
#+begin_src python
from scipy.stats import expon, uniform, poisson
# other stuff for the model
S = uniform(0, 2 / mu)
#+end_src
and for the simulator:
#+begin_src python
S = np.random.uniform(0, 2 / mu, size=len(A))
#+end_src
Run the code, and include your output.
#+end_exercise


** Effect of blocking on performance

#+begin_exercise
Take $\lambda=1$ and $\mu = 1.1$. Use the algorithm to compute the loss probability and $\E L$ for $T=5$, $T=10$ and $T=15$. Include the numbers.
#+begin_hint
Why is the loss probality equal to $\pi_{T}$?
#+end_hint
#+end_exercise

#+begin_exercise
Do the same computations for $\mu=0.5\lambda$. Why is the loss probability not so sensitive to $T$?
#+end_exercise

#+begin_exercise
Set $\mu=1.2\lambda$ again. Then compare the loss probability for $T=5, 10, 15$ for $S\sim \Exp{\mu}$ and $S\sim\Unif{0, 2/\mu}$. What is the influence of service time variability on the loss when $T=5$, $T=10$, $T=15$? Why is this influence relatively more important for larger $T$?
#+end_exercise



* Server control

With  blocking we control whether jobs are allowed to enter the system. We can also focus on another type of control, namely that of the server. Here we show how to simulate a system in which the server switches on when the waiting time exceeds a level $D$. When the server is empy again, it switches off.

Let us first plot the virtual waiting time.
Earlier we  discussed how to plot the virtual waiting time for a given array of waiting times, arrival times and departure times. Thus, the only relevant code is how to find the waiting time under a $D$ policy.

Note that we here use the letter $T$ to refer to the threshold since the letter $D$ is already given to the departure times.

#+begin_src python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(3)

num = 40
labda = 1
mu = 1.1 * labda
T = 10  # this acts as the threshold
X = np.random.exponential(scale=1 / labda, size=num)
X[0] = 0
A = np.zeros_like(X)
A = X.cumsum()
S = np.ones(len(A)) / mu
S[0] = 0
D = np.zeros_like(A)


W = np.zeros_like(S)
On = False
for k in range(1, len(S)):
    if On:
        W[k] = max(W[k - 1] + S[k - 1] - X[k], 0)
        On = False if W[k] <= 0 else True
    else:
        W[k] = W[k - 1] + S[k - 1]
        On = False if W[k] < T else True
    D[k] = A[k] + W[k] + S[k]

idx = np.where(W <= 0)[0]

empty = D[idx[1:] - 1]

E = np.zeros((2 * len(A) + len(empty), 2))  # epochs
E[: len(A), 0] = A
E[: len(A), 1] = W
E[len(A) : 2 * len(A), 0] = A
E[len(A) : 2 * len(A), 1] = W + S
E[2 * len(A) : 2 * len(A) + len(empty), 0] = empty
E[2 * len(A) : 2 * len(A) + len(empty), 1] = 0
E = E[np.lexsort((E[:, 1], E[:, 0]))]

plt.plot(E[:, 0], E[:, 1])
plt.savefig("figures/D-policy.pdf")
#+end_src

#+begin_exercise
Explain how the waiting times are computed.
#+end_exercise

Given cost $K$ to switch on the server and holding $h$ (per unit waiting time per unit time) we want to find the  threshold $T$ that minimizes the time-average cost. The code below shows how to compute the cost for a given $T$.

#+begin_src python
h = 1.0
K = 3
cost = 0
epoch, height = E[:, 0], E[:, 1]
for i in range(1, len(epoch)):
    dx = epoch[i] - epoch[i - 1]
    dy = (height[i] + height[i - 1]) / 2.0
    cost += h * dx * dy
    if dy == 0:
        cost += K
print(cost / D[-1])
#+end_src

#+begin_exercise
Explain how the code works. What is ~dx~, what is ~dy~? Why do we divide by $2$?
#+end_exercise

#+begin_exercise
Explain the procedure to find the best $T$.
#+end_exercise



* TODO Restore my emacs settings                                   :noexport:

#+begin_src emacs-lisp
(modus-themes-load-vivendi)
(set-face-attribute 'default nil :height 100)
#+end_src

#+RESULTS:

#+begin_src shell :results none
mv queues-with-control.pdf ../
#+end_src
